<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.2" />
<title>src.train_reg API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.train_reg</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
import pickle as pkl
from os.path import join as oj

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, RidgeCV
from sklearn.metrics import r2_score
from sklearn.model_selection import KFold
from sklearn.neural_network import MLPRegressor
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from statsmodels import robust
import features
import data
import config
from tqdm import tqdm
from scipy.stats import pearsonr, kendalltau
from neural_networks import neural_net_sklearn

#cell_nums_train = np.array([1, 2, 3, 4, 5])
#cell_nums_test = np.array([6])


def add_robust_features(df):
    df[&#39;X_95_quantile&#39;] = np.array([np.quantile(df.iloc[i].X, 0.95) for i in range(len(df))])
    df[&#39;X_mad&#39;] = np.array([robust.mad(df.iloc[i].X) for i in range(len(df))])
    return df


def log_transforms(df):
    
    df = add_robust_features(df)
    df[&#39;X_max_log&#39;] = np.log(df[&#39;X_max&#39;])
    df[&#39;X_95_quantile_log&#39;] = np.log(df[&#39;X_95_quantile&#39;] + 1)
    df[&#39;Y_max_log&#39;] = np.log(df[&#39;Y_max&#39;])
    df[&#39;X_mad_log&#39;] = np.log(df[&#39;X_mad&#39;])

    def calc_rise_log(x):
        idx_max = np.argmax(x)
        val_max = x[idx_max]
        rise = np.log(val_max) - np.log(abs(np.min(x[:idx_max + 1])) + 1)  # max change before peak
        return rise

    def calc_fall_log(x):
        idx_max = np.argmax(x)
        val_max = x[idx_max]
        fall = np.log(val_max) - np.log(abs(np.min(x[idx_max:])) + 1)  # drop after peak
        return fall

    df[&#39;rise_log&#39;] = np.array([calc_rise_log(df.iloc[i].X) for i in range(len(df))])
    df[&#39;fall_log&#39;] = np.array([calc_fall_log(df.iloc[i].X) for i in range(len(df))])
    num = 3
    df[&#39;rise_local_3_log&#39;] = df.apply(lambda row:
                                      calc_rise_log(np.array(row[&#39;X&#39;][max(0, row[&#39;X_peak_idx&#39;] - num):
                                                                      row[&#39;X_peak_idx&#39;] + num + 1])),
                                      axis=1)
    df[&#39;fall_local_3_log&#39;] = df.apply(lambda row:
                                      calc_fall_log(np.array(row[&#39;X&#39;][max(0, row[&#39;X_peak_idx&#39;] - num):
                                                                      row[&#39;X_peak_idx&#39;] + num + 1])),
                                      axis=1)

    num2 = 11
    df[&#39;rise_local_11_log&#39;] = df.apply(lambda row:
                                       calc_rise_log(np.array(row[&#39;X&#39;][max(0, row[&#39;X_peak_idx&#39;] - num2):
                                                                       row[&#39;X_peak_idx&#39;] + num2 + 1])),
                                       axis=1)
    df[&#39;fall_local_11_log&#39;] = df.apply(lambda row:
                                       calc_fall_log(np.array(row[&#39;X&#39;][max(0, row[&#39;X_peak_idx&#39;] - num2):
                                                                       row[&#39;X_peak_idx&#39;] + num2 + 1])),
                                       axis=1)
    return df

def add_sig_mean(df, resp_tracks=[&#39;Y&#39;]):
    &#34;&#34;&#34;
    add response of regression problem: mean auxilin strength among significant observations
    &#34;&#34;&#34;
    for track in resp_tracks:
        sig_mean = []
        for i in range(len(df)):
            r = df.iloc[i]
            sigs = np.array(r[f&#39;{track}_pvals&#39;]) &lt; 0.05
            if sum(sigs)&gt;0:
                sig_mean.append(np.mean(np.array(r[track])[sigs]))
            else:
                sig_mean.append(0)
        df[f&#39;{track}_sig_mean&#39;] = sig_mean
        df[f&#39;{track}_sig_mean_normalized&#39;] = sig_mean
        for cell in set(df[&#39;cell_num&#39;]):
            cell_idx = np.where(df[&#39;cell_num&#39;].values == cell)[0]
            y = df[f&#39;{track}_sig_mean_normalized&#39;].values[cell_idx]
            df[f&#39;{track}_sig_mean_normalized&#39;].values[cell_idx] = (y - np.mean(y))/np.std(y)
    return df


def train_reg(df, 
              feat_names, 
              model_type=&#39;rf&#39;, 
              outcome_def=&#39;Y_max_log&#39;,
              out_name=&#39;results/regression/test.pkl&#39;, 
              seed=42,
              **kwargs):
    &#39;&#39;&#39;
    train regression model
    
    hyperparameters of model can be specified using **kwargs
    &#39;&#39;&#39;
    np.random.seed(seed)
    X = df[feat_names]
    # X = (X - X.mean()) / X.std() # normalize the data
    y = df[outcome_def].values

    if model_type == &#39;rf&#39;:
        m = RandomForestRegressor(n_estimators=100)
    elif model_type == &#39;dt&#39;:
        m = DecisionTreeRegressor()
    elif model_type == &#39;linear&#39;:
        m = LinearRegression()
    elif model_type == &#39;ridge&#39;:
        m = RidgeCV()
    elif model_type == &#39;svm&#39;:
        m = SVR(gamma=&#39;scale&#39;)
    elif model_type == &#39;gb&#39;:
        m = GradientBoostingRegressor()
    elif model_type == &#39;irf&#39;:
        m = irf.ensemble.wrf()
    elif &#39;nn&#39; in model_type: # neural nets
        
        &#34;&#34;&#34;
        train fully connected neural network
        &#34;&#34;&#34;
        
        D_in = len(df[&#39;X_same_length&#39;].iloc[0])
        H = kwargs[&#39;fcnn_hidden_neurons&#39;] if &#39;fcnn_hidden_neurons&#39; in kwargs else 40
        epochs = kwargs[&#39;fcnn_epochs&#39;] if &#39;fcnn_epochs&#39; in kwargs else 1000
        batch_size = kwargs[&#39;fcnn_batch_size&#39;] if &#39;fcnn_batch_size&#39; in kwargs else 1000
        track_name = kwargs[&#39;track_name&#39;] if &#39;track_name&#39; in kwargs else &#39;X_same_length&#39;
        
        m = neural_net_sklearn(D_in=D_in, 
                             H=H, 
                             p=len(feat_names)-1,
                             epochs=epochs,
                             batch_size=batch_size,
                             track_name=track_name,
                             arch=model_type)

    # scores_cv = {s: [] for s in scorers.keys()}
    # scores_test = {s: [] for s in scorers.keys()}
    imps = {&#39;model&#39;: [], &#39;imps&#39;: []}

    cell_nums_train = np.array(list(set(df.cell_num.values)))
    kf = KFold(n_splits=len(cell_nums_train))

    # split testing data based on cell num
    #idxs_test = df.cell_num.isin(cell_nums_test)
    #idxs_train = df.cell_num.isin(cell_nums_train)
    #X_test, Y_test = X[idxs_test], y[idxs_test]
    num_pts_by_fold_cv = []
    y_preds = {}
    cv_score = []
    cv_pearsonr = []
    
    print(&#34;Looping over cv...&#34;)
    # loops over cv, where test set order is cell_nums_train[0], ..., cell_nums_train[-1]
    for cv_idx, cv_val_idx in tqdm(kf.split(cell_nums_train)):
        # get sample indices
        
        
        idxs_cv = df.cell_num.isin(cell_nums_train[np.array(cv_idx)])
        idxs_val_cv = df.cell_num.isin(cell_nums_train[np.array(cv_val_idx)])
        X_train_cv, Y_train_cv = X[idxs_cv], y[idxs_cv]
        X_val_cv, Y_val_cv = X[idxs_val_cv], y[idxs_val_cv]
        num_pts_by_fold_cv.append(X_val_cv.shape[0])

        # resample training data

        # fit
        m.fit(X_train_cv, Y_train_cv)

        # get preds
        preds = m.predict(X_val_cv)
        y_preds[cell_nums_train[np.array(cv_val_idx)][0]] = preds
        if &#39;log&#39; in outcome_def:
            cv_score.append(r2_score(np.exp(Y_val_cv), np.exp(preds)))
            cv_pearsonr.append(pearsonr(np.exp(Y_val_cv), np.exp(preds))[0])
        else:
            #print(r2_score(Y_val_cv, preds))
            cv_score.append(r2_score(Y_val_cv, preds))
            cv_pearsonr.append(pearsonr(Y_val_cv, preds)[0])
    
    print(&#34;Training with full data...&#34;)
    # cv_score = cv_score/len(cell_nums_train)
    m.fit(X, y)
    #print(cv_score)
    #test_preds = m.predict(X_test)
    results = {&#39;y_preds&#39;: y_preds,
               &#39;y&#39;: y,
               #&#39;test_preds&#39;: test_preds,
               &#39;cv&#39;: {&#39;r2&#39;: cv_score, &#39;pearsonr&#39;: cv_pearsonr},
               &#39;model_type&#39;: model_type,
               #&#39;model&#39;: m,
               &#39;num_pts_by_fold_cv&#39;: np.array(num_pts_by_fold_cv),
               }
    if model_type in [&#39;rf&#39;, &#39;linear&#39;, &#39;ridge&#39;, &#39;gb&#39;, &#39;svm&#39;, &#39;irf&#39;]:
        results[&#39;model&#39;] = m
    # save results
    # os.makedirs(out_dir, exist_ok=True)

    pkl.dump(results, open(out_name, &#39;wb&#39;))


def load_results(out_dir, by_cell=True):
    r = []
    for fname in os.listdir(out_dir):
        d = pkl.load(open(oj(out_dir, fname), &#39;rb&#39;))
        metrics = {k: d[&#39;cv&#39;][k] for k in d[&#39;cv&#39;].keys() if not &#39;curve&#39; in k}
        num_pts_by_fold_cv = d[&#39;num_pts_by_fold_cv&#39;]
        print(metrics)
        out = {k: np.average(metrics[k], weights=num_pts_by_fold_cv) for k in metrics}
        if by_cell:
            out.update({&#39;cv_accuracy_by_cell&#39;: metrics[&#39;r2&#39;]})
        out.update({k + &#39;_std&#39;: np.std(metrics[k]) for k in metrics})
        out[&#39;model_type&#39;] = fname.replace(&#39;.pkl&#39;, &#39;&#39;)  # d[&#39;model_type&#39;]
        print(d[&#39;cv&#39;].keys())
        # imp_mat = np.array(d[&#39;imps&#39;][&#39;imps&#39;])
        # imp_mu = imp_mat.mean(axis=0)
        # imp_sd = imp_mat.std(axis=0)

        # feat_names = d[&#39;feat_names_selected&#39;]
        # out.update({feat_names[i] + &#39;_f&#39;: imp_mu[i] for i in range(len(feat_names))})
        # out.update({feat_names[i]+&#39;_std_f&#39;: imp_sd[i] for i in range(len(feat_names))})
        r.append(pd.Series(out))
    r = pd.concat(r, axis=1, sort=False).T.infer_objects()
    r = r.reindex(sorted(r.columns), axis=1)  # sort the column names
    r = r.round(3)
    r = r.set_index(&#39;model_type&#39;)
    return r

def load_and_train(dset, outcome_def, out_dir, feat_names=None, use_processed=True):
    
    df = pd.read_pickle(f&#39;../data/tracks/tracks_{dset}.pkl&#39;)
    if dset == &#39;clath_aux_dynamin&#39;:
        df = df[df.catIdx.isin([1, 2])]
        df = df[df.lifetime &gt; 15]
    else:
        df = df[df[&#39;valid&#39;] == 1] 
    df = features.add_basic_features(df)
    df = log_transforms(df)
    df = add_sig_mean(df)
    df_train = df[df.cell_num.isin(config.DSETS[dset][&#39;train&#39;])] 
    df_test = df[df.cell_num.isin(config.DSETS[dset][&#39;test&#39;])] 
    df_train = df_train.dropna()
    
    #outcome_def = &#39;Z_sig_mean&#39;
    #out_dir = &#39;results/regression/Sep15&#39;
    os.makedirs(out_dir, exist_ok=True)
    if not feat_names:
        feat_names = data.get_feature_names(df_train)
        feat_names = [x for x in feat_names 
                      if not x.startswith(&#39;sc_&#39;) 
                      and not x.startswith(&#39;nmf_&#39;)
                      and not x in [&#39;center_max&#39;, &#39;left_max&#39;, &#39;right_max&#39;, &#39;up_max&#39;, &#39;down_max&#39;,
                                   &#39;X_max_around_Y_peak&#39;, &#39;X_max_after_Y_peak&#39;]
                      and not x.startswith(&#39;pc_&#39;)
                      and not &#39;log&#39; in x
                      and not &#39;binary&#39; in x
        #               and not &#39;slope&#39; in x
                     ]
    for model_type in tqdm([&#39;linear&#39;, &#39;gb&#39;, &#39;rf&#39;, &#39;svm&#39;, &#39;ridge&#39;]):
        out_name = f&#39;{model_type}&#39;
                        #print(out_name)
        if use_processed and os.path.exists(f&#39;{out_dir}/{out_name}.pkl&#39;):
            continue
        train_reg(df_train, feat_names=feat_names, model_type=model_type, 
                     outcome_def=outcome_def,
                     out_name=f&#39;{out_dir}/{out_name}.pkl&#39;)    
        
def test_reg(df, 
             model, 
             feat_names=None, 
             outcome_def=&#39;Y_max_log&#39;,
             out_name=&#39;results/regression/test.pkl&#39;, 
             seed=42):

    np.random.seed(seed)
    if not feat_names:
        feat_names = data.get_feature_names(df)
        feat_names = [x for x in feat_names 
                      if not x.startswith(&#39;sc_&#39;) 
                      and not x.startswith(&#39;nmf_&#39;)
                      and not x in [&#39;center_max&#39;, &#39;left_max&#39;, &#39;right_max&#39;, &#39;up_max&#39;, &#39;down_max&#39;,
                                   &#39;X_max_around_Y_peak&#39;, &#39;X_max_after_Y_peak&#39;]
                      and not x.startswith(&#39;pc_&#39;)
                      and not &#39;log&#39; in x
                      and not &#39;binary&#39; in x
        #               and not &#39;slope&#39; in x
                     ]
    X = df[feat_names]
    # X = (X - X.mean()) / X.std() # normalize the data
    test_preds = model.predict(X)
    results = {&#39;preds&#39;: test_preds}
    if outcome_def in df.keys():
        y = df[outcome_def].values
        results[&#39;r2&#39;] = r2_score(y, test_preds)
        results[&#39;pearsonr&#39;] = pearsonr(y, test_preds)
        results[&#39;kendalltau&#39;] = kendalltau(y, test_preds)
        
    return results</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="src.train_reg.add_robust_features"><code class="name flex">
<span>def <span class="ident">add_robust_features</span></span>(<span>df)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_robust_features(df):
    df[&#39;X_95_quantile&#39;] = np.array([np.quantile(df.iloc[i].X, 0.95) for i in range(len(df))])
    df[&#39;X_mad&#39;] = np.array([robust.mad(df.iloc[i].X) for i in range(len(df))])
    return df</code></pre>
</details>
</dd>
<dt id="src.train_reg.add_sig_mean"><code class="name flex">
<span>def <span class="ident">add_sig_mean</span></span>(<span>df, resp_tracks=['Y'])</span>
</code></dt>
<dd>
<section class="desc"><p>add response of regression problem: mean auxilin strength among significant observations</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_sig_mean(df, resp_tracks=[&#39;Y&#39;]):
    &#34;&#34;&#34;
    add response of regression problem: mean auxilin strength among significant observations
    &#34;&#34;&#34;
    for track in resp_tracks:
        sig_mean = []
        for i in range(len(df)):
            r = df.iloc[i]
            sigs = np.array(r[f&#39;{track}_pvals&#39;]) &lt; 0.05
            if sum(sigs)&gt;0:
                sig_mean.append(np.mean(np.array(r[track])[sigs]))
            else:
                sig_mean.append(0)
        df[f&#39;{track}_sig_mean&#39;] = sig_mean
        df[f&#39;{track}_sig_mean_normalized&#39;] = sig_mean
        for cell in set(df[&#39;cell_num&#39;]):
            cell_idx = np.where(df[&#39;cell_num&#39;].values == cell)[0]
            y = df[f&#39;{track}_sig_mean_normalized&#39;].values[cell_idx]
            df[f&#39;{track}_sig_mean_normalized&#39;].values[cell_idx] = (y - np.mean(y))/np.std(y)
    return df</code></pre>
</details>
</dd>
<dt id="src.train_reg.load_and_train"><code class="name flex">
<span>def <span class="ident">load_and_train</span></span>(<span>dset, outcome_def, out_dir, feat_names=None, use_processed=True)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_and_train(dset, outcome_def, out_dir, feat_names=None, use_processed=True):
    
    df = pd.read_pickle(f&#39;../data/tracks/tracks_{dset}.pkl&#39;)
    if dset == &#39;clath_aux_dynamin&#39;:
        df = df[df.catIdx.isin([1, 2])]
        df = df[df.lifetime &gt; 15]
    else:
        df = df[df[&#39;valid&#39;] == 1] 
    df = features.add_basic_features(df)
    df = log_transforms(df)
    df = add_sig_mean(df)
    df_train = df[df.cell_num.isin(config.DSETS[dset][&#39;train&#39;])] 
    df_test = df[df.cell_num.isin(config.DSETS[dset][&#39;test&#39;])] 
    df_train = df_train.dropna()
    
    #outcome_def = &#39;Z_sig_mean&#39;
    #out_dir = &#39;results/regression/Sep15&#39;
    os.makedirs(out_dir, exist_ok=True)
    if not feat_names:
        feat_names = data.get_feature_names(df_train)
        feat_names = [x for x in feat_names 
                      if not x.startswith(&#39;sc_&#39;) 
                      and not x.startswith(&#39;nmf_&#39;)
                      and not x in [&#39;center_max&#39;, &#39;left_max&#39;, &#39;right_max&#39;, &#39;up_max&#39;, &#39;down_max&#39;,
                                   &#39;X_max_around_Y_peak&#39;, &#39;X_max_after_Y_peak&#39;]
                      and not x.startswith(&#39;pc_&#39;)
                      and not &#39;log&#39; in x
                      and not &#39;binary&#39; in x
        #               and not &#39;slope&#39; in x
                     ]
    for model_type in tqdm([&#39;linear&#39;, &#39;gb&#39;, &#39;rf&#39;, &#39;svm&#39;, &#39;ridge&#39;]):
        out_name = f&#39;{model_type}&#39;
                        #print(out_name)
        if use_processed and os.path.exists(f&#39;{out_dir}/{out_name}.pkl&#39;):
            continue
        train_reg(df_train, feat_names=feat_names, model_type=model_type, 
                     outcome_def=outcome_def,
                     out_name=f&#39;{out_dir}/{out_name}.pkl&#39;)    </code></pre>
</details>
</dd>
<dt id="src.train_reg.load_results"><code class="name flex">
<span>def <span class="ident">load_results</span></span>(<span>out_dir, by_cell=True)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_results(out_dir, by_cell=True):
    r = []
    for fname in os.listdir(out_dir):
        d = pkl.load(open(oj(out_dir, fname), &#39;rb&#39;))
        metrics = {k: d[&#39;cv&#39;][k] for k in d[&#39;cv&#39;].keys() if not &#39;curve&#39; in k}
        num_pts_by_fold_cv = d[&#39;num_pts_by_fold_cv&#39;]
        print(metrics)
        out = {k: np.average(metrics[k], weights=num_pts_by_fold_cv) for k in metrics}
        if by_cell:
            out.update({&#39;cv_accuracy_by_cell&#39;: metrics[&#39;r2&#39;]})
        out.update({k + &#39;_std&#39;: np.std(metrics[k]) for k in metrics})
        out[&#39;model_type&#39;] = fname.replace(&#39;.pkl&#39;, &#39;&#39;)  # d[&#39;model_type&#39;]
        print(d[&#39;cv&#39;].keys())
        # imp_mat = np.array(d[&#39;imps&#39;][&#39;imps&#39;])
        # imp_mu = imp_mat.mean(axis=0)
        # imp_sd = imp_mat.std(axis=0)

        # feat_names = d[&#39;feat_names_selected&#39;]
        # out.update({feat_names[i] + &#39;_f&#39;: imp_mu[i] for i in range(len(feat_names))})
        # out.update({feat_names[i]+&#39;_std_f&#39;: imp_sd[i] for i in range(len(feat_names))})
        r.append(pd.Series(out))
    r = pd.concat(r, axis=1, sort=False).T.infer_objects()
    r = r.reindex(sorted(r.columns), axis=1)  # sort the column names
    r = r.round(3)
    r = r.set_index(&#39;model_type&#39;)
    return r</code></pre>
</details>
</dd>
<dt id="src.train_reg.log_transforms"><code class="name flex">
<span>def <span class="ident">log_transforms</span></span>(<span>df)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_transforms(df):
    
    df = add_robust_features(df)
    df[&#39;X_max_log&#39;] = np.log(df[&#39;X_max&#39;])
    df[&#39;X_95_quantile_log&#39;] = np.log(df[&#39;X_95_quantile&#39;] + 1)
    df[&#39;Y_max_log&#39;] = np.log(df[&#39;Y_max&#39;])
    df[&#39;X_mad_log&#39;] = np.log(df[&#39;X_mad&#39;])

    def calc_rise_log(x):
        idx_max = np.argmax(x)
        val_max = x[idx_max]
        rise = np.log(val_max) - np.log(abs(np.min(x[:idx_max + 1])) + 1)  # max change before peak
        return rise

    def calc_fall_log(x):
        idx_max = np.argmax(x)
        val_max = x[idx_max]
        fall = np.log(val_max) - np.log(abs(np.min(x[idx_max:])) + 1)  # drop after peak
        return fall

    df[&#39;rise_log&#39;] = np.array([calc_rise_log(df.iloc[i].X) for i in range(len(df))])
    df[&#39;fall_log&#39;] = np.array([calc_fall_log(df.iloc[i].X) for i in range(len(df))])
    num = 3
    df[&#39;rise_local_3_log&#39;] = df.apply(lambda row:
                                      calc_rise_log(np.array(row[&#39;X&#39;][max(0, row[&#39;X_peak_idx&#39;] - num):
                                                                      row[&#39;X_peak_idx&#39;] + num + 1])),
                                      axis=1)
    df[&#39;fall_local_3_log&#39;] = df.apply(lambda row:
                                      calc_fall_log(np.array(row[&#39;X&#39;][max(0, row[&#39;X_peak_idx&#39;] - num):
                                                                      row[&#39;X_peak_idx&#39;] + num + 1])),
                                      axis=1)

    num2 = 11
    df[&#39;rise_local_11_log&#39;] = df.apply(lambda row:
                                       calc_rise_log(np.array(row[&#39;X&#39;][max(0, row[&#39;X_peak_idx&#39;] - num2):
                                                                       row[&#39;X_peak_idx&#39;] + num2 + 1])),
                                       axis=1)
    df[&#39;fall_local_11_log&#39;] = df.apply(lambda row:
                                       calc_fall_log(np.array(row[&#39;X&#39;][max(0, row[&#39;X_peak_idx&#39;] - num2):
                                                                       row[&#39;X_peak_idx&#39;] + num2 + 1])),
                                       axis=1)
    return df</code></pre>
</details>
</dd>
<dt id="src.train_reg.test_reg"><code class="name flex">
<span>def <span class="ident">test_reg</span></span>(<span>df, model, feat_names=None, outcome_def='Y_max_log', out_name='results/regression/test.pkl', seed=42)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_reg(df, 
             model, 
             feat_names=None, 
             outcome_def=&#39;Y_max_log&#39;,
             out_name=&#39;results/regression/test.pkl&#39;, 
             seed=42):

    np.random.seed(seed)
    if not feat_names:
        feat_names = data.get_feature_names(df)
        feat_names = [x for x in feat_names 
                      if not x.startswith(&#39;sc_&#39;) 
                      and not x.startswith(&#39;nmf_&#39;)
                      and not x in [&#39;center_max&#39;, &#39;left_max&#39;, &#39;right_max&#39;, &#39;up_max&#39;, &#39;down_max&#39;,
                                   &#39;X_max_around_Y_peak&#39;, &#39;X_max_after_Y_peak&#39;]
                      and not x.startswith(&#39;pc_&#39;)
                      and not &#39;log&#39; in x
                      and not &#39;binary&#39; in x
        #               and not &#39;slope&#39; in x
                     ]
    X = df[feat_names]
    # X = (X - X.mean()) / X.std() # normalize the data
    test_preds = model.predict(X)
    results = {&#39;preds&#39;: test_preds}
    if outcome_def in df.keys():
        y = df[outcome_def].values
        results[&#39;r2&#39;] = r2_score(y, test_preds)
        results[&#39;pearsonr&#39;] = pearsonr(y, test_preds)
        results[&#39;kendalltau&#39;] = kendalltau(y, test_preds)
        
    return results</code></pre>
</details>
</dd>
<dt id="src.train_reg.train_reg"><code class="name flex">
<span>def <span class="ident">train_reg</span></span>(<span>df, feat_names, model_type='rf', outcome_def='Y_max_log', out_name='results/regression/test.pkl', seed=42, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>train regression model</p>
<p>hyperparameters of model can be specified using **kwargs</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_reg(df, 
              feat_names, 
              model_type=&#39;rf&#39;, 
              outcome_def=&#39;Y_max_log&#39;,
              out_name=&#39;results/regression/test.pkl&#39;, 
              seed=42,
              **kwargs):
    &#39;&#39;&#39;
    train regression model
    
    hyperparameters of model can be specified using **kwargs
    &#39;&#39;&#39;
    np.random.seed(seed)
    X = df[feat_names]
    # X = (X - X.mean()) / X.std() # normalize the data
    y = df[outcome_def].values

    if model_type == &#39;rf&#39;:
        m = RandomForestRegressor(n_estimators=100)
    elif model_type == &#39;dt&#39;:
        m = DecisionTreeRegressor()
    elif model_type == &#39;linear&#39;:
        m = LinearRegression()
    elif model_type == &#39;ridge&#39;:
        m = RidgeCV()
    elif model_type == &#39;svm&#39;:
        m = SVR(gamma=&#39;scale&#39;)
    elif model_type == &#39;gb&#39;:
        m = GradientBoostingRegressor()
    elif model_type == &#39;irf&#39;:
        m = irf.ensemble.wrf()
    elif &#39;nn&#39; in model_type: # neural nets
        
        &#34;&#34;&#34;
        train fully connected neural network
        &#34;&#34;&#34;
        
        D_in = len(df[&#39;X_same_length&#39;].iloc[0])
        H = kwargs[&#39;fcnn_hidden_neurons&#39;] if &#39;fcnn_hidden_neurons&#39; in kwargs else 40
        epochs = kwargs[&#39;fcnn_epochs&#39;] if &#39;fcnn_epochs&#39; in kwargs else 1000
        batch_size = kwargs[&#39;fcnn_batch_size&#39;] if &#39;fcnn_batch_size&#39; in kwargs else 1000
        track_name = kwargs[&#39;track_name&#39;] if &#39;track_name&#39; in kwargs else &#39;X_same_length&#39;
        
        m = neural_net_sklearn(D_in=D_in, 
                             H=H, 
                             p=len(feat_names)-1,
                             epochs=epochs,
                             batch_size=batch_size,
                             track_name=track_name,
                             arch=model_type)

    # scores_cv = {s: [] for s in scorers.keys()}
    # scores_test = {s: [] for s in scorers.keys()}
    imps = {&#39;model&#39;: [], &#39;imps&#39;: []}

    cell_nums_train = np.array(list(set(df.cell_num.values)))
    kf = KFold(n_splits=len(cell_nums_train))

    # split testing data based on cell num
    #idxs_test = df.cell_num.isin(cell_nums_test)
    #idxs_train = df.cell_num.isin(cell_nums_train)
    #X_test, Y_test = X[idxs_test], y[idxs_test]
    num_pts_by_fold_cv = []
    y_preds = {}
    cv_score = []
    cv_pearsonr = []
    
    print(&#34;Looping over cv...&#34;)
    # loops over cv, where test set order is cell_nums_train[0], ..., cell_nums_train[-1]
    for cv_idx, cv_val_idx in tqdm(kf.split(cell_nums_train)):
        # get sample indices
        
        
        idxs_cv = df.cell_num.isin(cell_nums_train[np.array(cv_idx)])
        idxs_val_cv = df.cell_num.isin(cell_nums_train[np.array(cv_val_idx)])
        X_train_cv, Y_train_cv = X[idxs_cv], y[idxs_cv]
        X_val_cv, Y_val_cv = X[idxs_val_cv], y[idxs_val_cv]
        num_pts_by_fold_cv.append(X_val_cv.shape[0])

        # resample training data

        # fit
        m.fit(X_train_cv, Y_train_cv)

        # get preds
        preds = m.predict(X_val_cv)
        y_preds[cell_nums_train[np.array(cv_val_idx)][0]] = preds
        if &#39;log&#39; in outcome_def:
            cv_score.append(r2_score(np.exp(Y_val_cv), np.exp(preds)))
            cv_pearsonr.append(pearsonr(np.exp(Y_val_cv), np.exp(preds))[0])
        else:
            #print(r2_score(Y_val_cv, preds))
            cv_score.append(r2_score(Y_val_cv, preds))
            cv_pearsonr.append(pearsonr(Y_val_cv, preds)[0])
    
    print(&#34;Training with full data...&#34;)
    # cv_score = cv_score/len(cell_nums_train)
    m.fit(X, y)
    #print(cv_score)
    #test_preds = m.predict(X_test)
    results = {&#39;y_preds&#39;: y_preds,
               &#39;y&#39;: y,
               #&#39;test_preds&#39;: test_preds,
               &#39;cv&#39;: {&#39;r2&#39;: cv_score, &#39;pearsonr&#39;: cv_pearsonr},
               &#39;model_type&#39;: model_type,
               #&#39;model&#39;: m,
               &#39;num_pts_by_fold_cv&#39;: np.array(num_pts_by_fold_cv),
               }
    if model_type in [&#39;rf&#39;, &#39;linear&#39;, &#39;ridge&#39;, &#39;gb&#39;, &#39;svm&#39;, &#39;irf&#39;]:
        results[&#39;model&#39;] = m
    # save results
    # os.makedirs(out_dir, exist_ok=True)

    pkl.dump(results, open(out_name, &#39;wb&#39;))</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src" href="index.html">src</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="src.train_reg.add_robust_features" href="#src.train_reg.add_robust_features">add_robust_features</a></code></li>
<li><code><a title="src.train_reg.add_sig_mean" href="#src.train_reg.add_sig_mean">add_sig_mean</a></code></li>
<li><code><a title="src.train_reg.load_and_train" href="#src.train_reg.load_and_train">load_and_train</a></code></li>
<li><code><a title="src.train_reg.load_results" href="#src.train_reg.load_results">load_results</a></code></li>
<li><code><a title="src.train_reg.log_transforms" href="#src.train_reg.log_transforms">log_transforms</a></code></li>
<li><code><a title="src.train_reg.test_reg" href="#src.train_reg.test_reg">test_reg</a></code></li>
<li><code><a title="src.train_reg.train_reg" href="#src.train_reg.train_reg">train_reg</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.2</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>