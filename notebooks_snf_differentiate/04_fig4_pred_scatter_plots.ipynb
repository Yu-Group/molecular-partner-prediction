{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get predictions and outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This script re-fits all non-LSTM models and evaluates them for each cell / dataset.\n",
    "It also takes a pre-trained LSTM and evaluates it on each cell / dataset.\n",
    "'''\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import data\n",
    "# from os.path import join as oj\n",
    "# import sys\n",
    "\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# sys.path.append('../src')\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import scipy\n",
    "# from matplotlib import pyplot as plt\n",
    "# from sklearn import metrics\n",
    "# import data\n",
    "# from config import *\n",
    "# from tqdm import tqdm\n",
    "# import pickle as pkl\n",
    "# import train_reg\n",
    "# from copy import deepcopy\n",
    "# import config\n",
    "# import models\n",
    "# import pandas as pd\n",
    "# import features\n",
    "# import outcomes\n",
    "# import neural_networks\n",
    "# from sklearn.model_selection import KFold\n",
    "# from torch import nn, optim\n",
    "# from torch.nn import functional as F\n",
    "# from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "# from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "# from sklearn.svm import SVR\n",
    "# from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, feat_names = data.get_snf_mt_vs_wt()\n",
    "epoch = 10    \n",
    "feat_name = feat_names[0]\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "for df in [df_train, df_test]:\n",
    "    print(df['mt'].value_counts())\n",
    "\n",
    "\n",
    "outcome = 'mt'\n",
    "outcome_def = 'mt'\n",
    "outcome_binary = 'mt'\n",
    "                \n",
    "# print(\"computing predictions for lstm\")                 \n",
    "models.append('lstm')\n",
    "checkpoint_fname = f'../models/vps_distingish_mt_vs_wt_epoch={epoch}.pkl'\n",
    "results = pkl.load(open(checkpoint_fname, 'rb'))\n",
    "dnn = neural_networks.neural_net_sklearn(\n",
    "    D_in=40, H=20, p=0, arch='lstm', track_name=feat_name)\n",
    "dnn.model.load_state_dict(results['model_state_dict'])\n",
    "\n",
    "df = df_test\n",
    "X = df[[feat_name]]\n",
    "y_reg = df[outcome_def] # df['Y_sig_mean_normalized'].values\n",
    "y = df[outcome_binary].values\n",
    "#preds = np.logical_and(dnn.predict(X), df['X_max'] > 1500).values.astype(int)  \n",
    "preds = dnn.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter plot\n",
    "Show that preds correlates with common features and that erors are where vps may not get recruited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shapes', y.shape, preds.shape, f'{pd.Series(y).value_counts()=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(preds[y==0], label='wt')\n",
    "plt.hist(preds[y==1], label='mt')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel(\"Count (test)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = df['mt'].values\n",
    "\n",
    "# plt.axhline(0, color='gray', alpha=0.5)\n",
    "plt.yticks([])\n",
    "correct = ((preds>0.5) == ys)\n",
    "err = ~correct\n",
    "plt.plot(df['Y_sig_mean'][correct], preds[correct], '.', alpha=0.1, markeredgewidth=0) #, c=df['preds'], **kwargs)\n",
    "plt.plot(df['Y_sig_mean'][err], preds[err], '.', alpha=1, markeredgewidth=0) #, c=df['preds'], **kwargs)\n",
    "plt.xlabel('Mean fitted vps amplitude')\n",
    "plt.ylabel('Predicted Prob(mt)')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = df['mt'].values\n",
    "# preds_perc = [percentileofscore(ys, score=p) for p in preds]\n",
    "preds_perc = preds\n",
    "# df['preds'] = \n",
    "\n",
    "R, C = 2, 3\n",
    "plt.figure(figsize=(C * 4.5, R * 3))\n",
    "\n",
    "plt.subplot(R, C, 1)\n",
    "# plt.axhline(0, color='gray', alpha=0.5)\n",
    "plt.plot(df['X_max'], preds_perc, '.', alpha=0.1, markeredgewidth=0)\n",
    "# cs=df['mt'].map({0: 'blue', 1: 'orange'}).values.tolist()) #, c=df['preds'], **kwargs)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Max fitted snf7 amplitude')\n",
    "plt.ylabel('Predicted Prob(mt)\\n')\n",
    "plt.title('A', loc='left', fontweight='bold')\n",
    "\n",
    "plt.subplot(R, C, 2)\n",
    "# plt.axhline(0, color='gray', alpha=0.5)\n",
    "plt.yticks([])\n",
    "plt.plot(df['Y_sig_mean'], preds_perc, '.', alpha=0.1, markeredgewidth=0) #, c=df['preds'], **kwargs)\n",
    "plt.xlabel('Mean fitted vps amplitude')\n",
    "plt.xscale('log')\n",
    "plt.title('B', loc='left', fontweight='bold')\n",
    "\n",
    "plt.subplot(R, C, 3)\n",
    "# plt.axhline(0, color='gray', alpha=0.5)\n",
    "plt.plot(df['X_d1'], preds_perc, '.', alpha=0.1, markeredgewidth=0) #, c=df['preds'], **kwargs)\n",
    "plt.xlabel('DASC (D1)')\n",
    "plt.yticks([])\n",
    "plt.title('C', loc='left', fontweight='bold')\n",
    "\n",
    "plt.subplot(R, C, 4)\n",
    "# plt.axhline(0, color='gray', alpha=0.5)\n",
    "plt.plot(df['lifetime'], preds_perc, '.', alpha=0.1, markeredgewidth=0) #, c=df['preds'], **kwargs)\n",
    "plt.xlabel('Lifetime (sec)')\n",
    "# plt.ylabel('Predicted auxilin\\nsignal strength')\n",
    "# plt.yticks([])\n",
    "plt.title('D', loc='left', fontweight='bold')\n",
    "\n",
    "plt.subplot(R, C, 5)\n",
    "# plt.axhline(0, color='gray', alpha=0.5)\n",
    "plt.plot(df['X_peak_idx'], preds_perc, '.', alpha=0.1, markeredgewidth=0) #, c=df['preds'], **kwargs)\n",
    "plt.xlabel('Time to snf7 peak (sec)')\n",
    "plt.yticks([])\n",
    "plt.title('E', loc='left', fontweight='bold')\n",
    "\n",
    "plt.subplot(R, C, 6)\n",
    "plt.axhline(0, color='gray', alpha=0.5)\n",
    "plt.plot(df['mean_total_displacement'], preds_perc, '.', alpha=0.1, markeredgewidth=0) #, c=df['preds'], **kwargs)\n",
    "plt.xlabel('Mean displacement')\n",
    "plt.yticks([])\n",
    "plt.title('F', loc='left', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "# viz.savefig('top_feats_scatter')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('.aux': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "48564b99b2d05f0d8880381521ddeeac4759e29c1bcb4036563094615a093164"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
