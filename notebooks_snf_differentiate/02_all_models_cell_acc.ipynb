{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "#import dvu\n",
    "import os\n",
    "from os.path import join as oj\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import viz\n",
    "import numpy as np\n",
    "#import torch\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "import data\n",
    "from config import *\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import train_reg\n",
    "from copy import deepcopy\n",
    "import config\n",
    "import models\n",
    "import pandas as pd\n",
    "import features\n",
    "import outcomes\n",
    "import neural_networks\n",
    "from sklearn.model_selection import KFold\n",
    "#from torch import nn, optim\n",
    "#from torch.nn import functional as F\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn.svm import SVR\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare all different models across dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../reports/cell_vps_level_res_y_consec_sig.csv\n",
      "../reports/dataset_vps_level_res_y_consec_sig.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../reports/*vps*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = '_y_consec_sig' # '_successful', _successful_dynamin, _successful_full # '' choose which outcome to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv(f\"../reports/dataset_vps_level_res{suffix}.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv(f\"../reports/dataset_vps_level_res{suffix}.csv\", index_col=0)\n",
    "res = res.round(3)\n",
    "# res = res[[c for c in res.columns if 'balanced' not in c]]\n",
    "# print(res)\n",
    "res = res.transpose()\n",
    "res = res[['gb_basic', 'rf_basic', 'svm_basic', 'svm_dasc', 'lstm']]\n",
    "num_cells = pkl.load(open(\"../reports/num_tracks_by_cell.pkl\", \"rb\"))\n",
    "# res.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv(f\"../reports/cell_vps_level_res{suffix}.csv\", index_col=0)\n",
    "plot_label = {\"accuracy\": \"accuracy\", \"f1\": \"F1 score\", \"roc_auc\": \"ROC AUC\"}\n",
    "res = res[[c for c in res.columns if not 'balanced' in c]]\n",
    "\n",
    "for metric in ['accuracy', 'f1', 'roc_auc']:\n",
    "    res_metric = res[[c for c in res.columns if metric in c]]\n",
    "    baseline = 'svm_dasc'\n",
    "    for baseline in ['svm_dasc', 'gb_basic']:\n",
    "\n",
    "        plt.figure(dpi=200, figsize=(4, 3))\n",
    "        plt.grid(zorder=-1.0)\n",
    "        plt.scatter(res.loc[baseline].values, \n",
    "                    res.loc['lstm'].values, \n",
    "                    color='#E26595',\n",
    "                    label='Cells with dynamin marker',\n",
    "                    alpha=.8)\n",
    "        \n",
    "        lowerlim = min(res_metric.loc[baseline].values) - 0.03\n",
    "        upperlim = max(res_metric.loc['lstm'].values) + 0.03\n",
    "        plt.xlim((lowerlim, upperlim))\n",
    "        plt.ylim((lowerlim, upperlim))\n",
    "        if baseline == 'svm_dasc':\n",
    "            plt.xlabel(f\"DASC {plot_label[metric]}\")\n",
    "        else:\n",
    "            plt.xlabel(f\"Gradient boosting {plot_label[metric]}\")\n",
    "        plt.ylabel(f\"LSTM {plot_label[metric]}\")\n",
    "        plt.legend(loc='lower right', fontsize='small', framealpha=1, edgecolor='black')\n",
    "        plt.plot((lowerlim, upperlim), (lowerlim, upperlim), '--', color='k', alpha=.5)\n",
    "#         viz.savefig(f'lstm_{baseline}_{metric}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>test_corr</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gb_basic</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb_dasc</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_basic</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_dasc</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge_basic</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge_dasc</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_basic</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_dasc</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             test_accuracy  test_roc_auc  test_r2  test_corr  test_recall  \\\n",
       "gb_basic              0.55          0.72     0.13       0.39         0.81   \n",
       "gb_dasc               0.37          0.69    -0.25       0.26         0.92   \n",
       "rf_basic              0.47          0.73     0.06       0.38         0.87   \n",
       "rf_dasc               0.42          0.62    -0.47       0.18         0.85   \n",
       "ridge_basic           0.46          0.74     0.12       0.41         0.88   \n",
       "ridge_dasc            0.36          0.71    -0.10       0.32         0.92   \n",
       "svm_basic             0.78          0.72     0.05       0.36         0.36   \n",
       "svm_dasc              0.55          0.71    -0.02       0.32         0.80   \n",
       "lstm                  0.63          0.72     0.13       0.37         0.74   \n",
       "\n",
       "             test_f1  \n",
       "gb_basic        0.37  \n",
       "gb_dasc         0.33  \n",
       "rf_basic        0.36  \n",
       "rf_dasc         0.33  \n",
       "ridge_basic     0.36  \n",
       "ridge_dasc      0.33  \n",
       "svm_basic       0.36  \n",
       "svm_dasc        0.38  \n",
       "lstm            0.40  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.round(2) #.style.background_gradient()\n",
    "# res.round(2).style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
