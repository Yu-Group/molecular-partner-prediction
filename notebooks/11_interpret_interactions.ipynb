{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from os.path import join as oj\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "# plt.style.use('dark_background')\n",
    "import data\n",
    "from skorch.callbacks import Checkpoint\n",
    "from skorch import NeuralNetRegressor\n",
    "from config import *\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import train_reg\n",
    "from math import floor\n",
    "from copy import deepcopy\n",
    "import config\n",
    "import models\n",
    "import pandas as pd\n",
    "import features\n",
    "from scipy.stats import skew, pearsonr\n",
    "import outcomes\n",
    "import neural_networks\n",
    "from sklearn.model_selection import KFold\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import interpret\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently trained only on 'clath_aux+gak_a7d2_new'\n",
    "dsets = ['clath_aux+gak_new']\n",
    "splits = ['test']\n",
    "feat_names = ['X_same_length_normalized'] # + data.select_final_feats(data.get_feature_names(df))\n",
    "              #['mean_total_displacement', 'mean_square_displacement', 'lifetime']\n",
    "meta = ['cell_num', 'Y_sig_mean', 'Y_sig_mean_normalized']\n",
    "dfs = data.load_dfs_for_lstm(dsets=dsets, splits=splits, meta=meta)\n",
    "\n",
    "# load model\n",
    "p = 1\n",
    "results = pkl.load(open(config.FINAL_MODEL, 'rb'))\n",
    "dnn = neural_networks.neural_net_sklearn(D_in=40, H=20, p=p-1, arch='lstm')\n",
    "dnn.model.load_state_dict(results['model_state_dict'])\n",
    "\n",
    "# load data\n",
    "# df = dfs[('clath_aux+gak_a7d2', 'train')]\n",
    "df = dfs[('clath_aux+gak_new', 'test')]\n",
    "X = df[feat_names[:p]]\n",
    "y = df['y_consec_thresh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8246445497630331\n"
     ]
    }
   ],
   "source": [
    "track_name = 'X_same_length_normalized'\n",
    "track_name_unnormalized = 'X_same_length'\n",
    "df = dfs[('clath_aux+gak_new', 'test')]\n",
    "df['preds'] = dnn.predict(df[feat_names[:1]])\n",
    "df = df.sort_values(by='preds')\n",
    "x = df[feat_names[:1]]\n",
    "y = df['y_consec_thresh'].values\n",
    "preds = dnn.predict(x)\n",
    "n = df.shape[0]\n",
    "\n",
    "m = 40\n",
    "xtrack_unnormalized = df[track_name_unnormalized]\n",
    "xtrack = x[track_name]\n",
    "xtrack_t = torch.tensor(np.array(list(xtrack.values)), dtype=torch.float)\n",
    "xfeats = x[[c for c in x.columns if c != track_name]]\n",
    "xfeats_t = torch.tensor(np.array(xfeats).astype(float), dtype=torch.float)\n",
    "\n",
    "\n",
    "# sort things\n",
    "print('acc', np.mean((preds > 0) == y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all cd scores\n",
    "cd_score_path = f'../data/outputs/all_cd_scores_clath_aux+gak_new_test.pkl'\n",
    "if os.path.exists(cd_score_path):\n",
    "    all_cd_scores = pd.read_pickle(cd_score_path)\n",
    "else:\n",
    "    all_cd_scores = {}\n",
    "    for s in tqdm(range(m)):\n",
    "        for e in range(s+1, m+1):\n",
    "            all_cd_scores[(s, e)] = interpret.calc_cd_score(xtrack_t, xfeats_t, s, e, dnn.model)\n",
    "    with open(cd_score_path, 'wb') as handle:\n",
    "        pkl.dump(all_cd_scores, handle, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-36b8292aa96f>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  all_res = np.array(all_res)\n"
     ]
    }
   ],
   "source": [
    "# find best segmentations\n",
    "all_res = []\n",
    "for i in range(len(x)):\n",
    "    cd_scores_list = np.zeros((m, m))\n",
    "    for s in (range(m)):\n",
    "        for e in range(s + 1, m + 1):            \n",
    "            cd_scores_list[s][e-1] = all_cd_scores[(s, e)][i]\n",
    "    res, paths = interpret.max_abs_sum_seg(cd_scores_list, min_length=5)\n",
    "    lt = np.sum(np.array(df[track_name_unnormalized].values[i]) != 0)\n",
    "    #all_res.append(paths[lt-1])\n",
    "    all_res.append(paths[m - 1])\n",
    "    #print(res[lt-1], paths[lt-1])\n",
    "\n",
    "# paths is a list of lists, where each list contains all the starting point for segments    \n",
    "all_res = np.array(all_res)    \n",
    "    \n",
    "def extract_segs_and_scores(all_res, all_cd_scores, i):\n",
    "    '''\n",
    "    Params\n",
    "    ------\n",
    "    all_res: array_like\n",
    "        list of list of starting points for all segments\n",
    "    '''\n",
    "    segs = [(all_res[i][j], all_res[i][j+1]) # converting starting points to list of (start, end) pairs\n",
    "            for j in range(len(all_res[i]) - 1)\n",
    "           ] + [(all_res[i][-1], 40)]\n",
    "    scores = [all_cd_scores[(s, e)][i][0]\n",
    "              for (s, e) in segs]\n",
    "    return segs, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for which_tracks in ['aux-', 'aux+', 'random']: # random, neg, pos\n",
    "    C, R = 3, 5\n",
    "\n",
    "    # calculate vabs\n",
    "    scores_all = [extract_segs_and_scores(all_res, all_cd_scores, i)[1] for i in range(all_res.size)]\n",
    "    vmax = max([max(x) for x in scores_all])\n",
    "    vmin = min([min(x) for x in scores_all])\n",
    "    vabs = max(abs(vmax), abs(vmin)) / 2 # note this /2 thresholds things\n",
    "\n",
    "    plt.figure(dpi=150, figsize=(2 * C, 1 * R), facecolor='w')\n",
    "    i = 0\n",
    "    for r in range(0, R):\n",
    "        for c in range(0, C):\n",
    "            ax = plt.subplot(R, C, i + 1)\n",
    "            if which_tracks == 'random':\n",
    "                arg = np.random.permutation(np.arange(n))\n",
    "            elif which_tracks == 'aux-':\n",
    "                arg = np.arange(n)\n",
    "            elif which_tracks == 'aux+':\n",
    "                arg = np.arange(n)[::-1]\n",
    "            segs, scores = extract_segs_and_scores(all_res, all_cd_scores, arg[i])\n",
    "        #     print('scores', segs, scores, preds[arg][i])\n",
    "            interpret.plot_segs(track_segs=segs,\n",
    "                                cd_scores=scores,\n",
    "                                xtrack=xtrack_unnormalized.iloc[arg[i]],\n",
    "        #                         pred=preds[arg][i],\n",
    "        #                         y=y[arg][i],\n",
    "                                vabs=vabs,\n",
    "                                cbar=False,\n",
    "                                xticks=(c==0 and r==R-1),\n",
    "                                yticks=i==0)\n",
    "            if which_tracks in ['aux+', 'random']:\n",
    "                plt.ylim((-100, 10000))\n",
    "            else:\n",
    "                plt.ylim((-100, 2000))\n",
    "            plt.suptitle(which_tracks + ' predictions')\n",
    "            i += 1\n",
    "    plt.tight_layout()\n",
    "    viz.savefig('interpretations_' + which_tracks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.05, 0.80, 0.9, 0.1])\n",
    "cb = mpl.colorbar.ColorbarBase(ax, orientation='horizontal', \n",
    "                    norm=matplotlib.colors.Normalize(vmin=-vabs, vmax=vabs),\n",
    "                               cmap=viz.cmap)\n",
    "cb.ax.set_xlabel('Contribution to aux+ prediction (CD score)')\n",
    "viz.savefig('interpretations_cbar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**make simple illustrative plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 98\n",
    "plt.figure(figsize=(2.4, 1.9), facecolor='w', dpi=300)\n",
    "segs, scores = extract_segs_and_scores(all_res, all_cd_scores, i)\n",
    "cb = interpret.plot_segs(track_segs=segs, cd_scores=scores, xtrack=xtrack_unnormalized.iloc[i])\n",
    "cb.set_ticks([])\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "plt.show()\n",
    "#               pred=dnn.predict(x)[i],\n",
    "#               y=y.values[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**recalculate with normalized scores (there is some err here)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cd_scores_normalized = {}\n",
    "for s in tqdm(range(m)):\n",
    "    for e in range(s + 1, m + 1):\n",
    "        x = all_cd_scores[(s, e)]\n",
    "        x = x.reshape(1, -1)[0]\n",
    "        all_cd_scores_normalized[(s, e)] = np.abs((x - np.mean(x)) / np.std(x))\n",
    "        \n",
    "for i in range(len(df)):\n",
    "    cd_scores_list = np.zeros((m, m))\n",
    "    s0, e0 = 0, 0\n",
    "    m = 0\n",
    "    lt = np.sum(np.array(df[track_name_unnormalized].values[i]) != 0)\n",
    "    for s in (range(lt)):\n",
    "        for e in range(s+1, lt):            \n",
    "            cd_scores_list[s][e-1] = all_cd_scores_normalized[(s, e)][i]\n",
    "            if cd_scores_list[s][e-1] > m:\n",
    "                m = cd_scores_list[s][e-1]\n",
    "                s0, e0 = s, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/all_cd_scores_clath_aux+gak_new_test.pkl', 'wb') as handle:\n",
    "    pkl.dump(all_cd_scores, handle, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interpret one pred at multiple scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_segs(track_segs, cd_scores, xtrack, pred):\n",
    "    cm = sns.diverging_palette(22, 220, as_cmap=True, center='light')\n",
    "    vabs = np.max(np.abs(cd_scores))\n",
    "    # plt.plot(xtrack, zorder=0, lw=2, color='#111111')\n",
    "    for i in range(len(track_segs)):\n",
    "        (s, e) = track_segs[i]\n",
    "        cd_score = cd_scores[i]\n",
    "        seq_len = e - s\n",
    "        xs = np.arange(s, e)\n",
    "        norm = matplotlib.colors.Normalize(vmin=-vabs, vmax=vabs)\n",
    "        if seq_len > 1:\n",
    "            cd_score = [cd_score] * seq_len\n",
    "            plt.plot(xs, xtrack[s: e], zorder=0, lw=2, color=cm(norm(cd_score[0])), alpha=0.5)\n",
    "        plt.scatter(xs, xtrack[s: e],\n",
    "                    c=cd_score, cmap=cm, vmin=-vabs, vmax=vabs, s=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_name = 'X_same_length_normalized'\n",
    "track_name_unnormalized = 'X_same_length'\n",
    "num = 100\n",
    "x = X.iloc[num: num + 1]\n",
    "xtrack_unnormalized = df.iloc[num: num + 1][track_name_unnormalized]\n",
    "xtrack = x[track_name]\n",
    "xtrack_t = torch.tensor(np.array(list(xtrack.values)), dtype=torch.float)\n",
    "xfeats = x[[c for c in x.columns if c != track_name]]\n",
    "xfeats_t = torch.tensor(np.array(xfeats).astype(float), dtype=torch.float)\n",
    "pred = dnn.model(xtrack_t, xfeats_t).item()\n",
    "#print(f'pred {pred:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [00:02<00:11,  2.35s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:04<00:08,  2.24s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [00:05<00:05,  1.94s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:06<00:03,  1.58s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:06<00:01,  1.26s/it]\u001b[A\n",
      "100%|██████████| 6/6 [00:07<00:00,  1.17s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "T = 40 # seq len\n",
    "# track_segs = [(s, s + 1) for s in range(T)]\n",
    "DIV = 40\n",
    "track_segs_fourty = [(floor(s * T / DIV), floor((s+1) * T / DIV))\n",
    "                    for s in range(DIV)]\n",
    "\n",
    "DIV = 20\n",
    "track_segs_twenty = [(floor(s * T / DIV), floor((s+1) * T / DIV))\n",
    "                    for s in range(DIV)]\n",
    "DIV = 10\n",
    "track_segs_tenths = [(floor(s * T / DIV), floor((s+1) * T / DIV))\n",
    "                    for s in range(DIV)]\n",
    "DIV = 6\n",
    "track_segs_fifths = [(floor(s * T / DIV), floor((s+1) * T / DIV))\n",
    "                    for s in range(DIV)]\n",
    "DIV = 4\n",
    "track_segs_quarters = [(floor(s * T / DIV), floor((s+1) * T / DIV))\n",
    "                    for s in range(DIV)]\n",
    "DIV = 1\n",
    "track_segs_full = [(floor(s * T / DIV), floor((s+1) * T / DIV))\n",
    "                    for s in range(DIV)]\n",
    "track_segs_list = [track_segs_fourty, track_segs_twenty, track_segs_tenths,\n",
    "                   track_segs_fifths, track_segs_quarters, track_segs_full]\n",
    "cd_scores_list = [[interpret.calc_cd_score(xtrack_t, xfeats_t, s, e, dnn.model)\n",
    "                  for (s, e) in track_segs]\n",
    "                  for track_segs in tqdm(track_segs_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=200, figsize=(12, 6))\n",
    "R, C = 2, 3\n",
    "for i, track_segs in enumerate(track_segs_list):\n",
    "    ax = plt.subplot(R, C, i + 1)\n",
    "    cd_scores = cd_scores_list[i]\n",
    "    interpret.plot_segs(track_segs, cd_scores, xtrack_unnormalized.iloc[0], pred, y=0)\n",
    "    \n",
    "    if i == C * (R - 1):\n",
    "        plt.xlabel('Time')\n",
    "    else:\n",
    "        plt.xticks([])\n",
    "    if i == 0:\n",
    "        plt.ylabel('Clath Amplitude')\n",
    "    else:\n",
    "        plt.yticks([])\n",
    "    if i  == C - 1:\n",
    "        plt.colorbar(label='CD Score')\n",
    "    else:\n",
    "        plt.colorbar()\n",
    "    if i ==  C * R - 1:\n",
    "        plt.text(0.6, 0.9,\n",
    "                 f'Pred: {pred:.2f}', fontsize='x-large', transform = ax.transAxes)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
